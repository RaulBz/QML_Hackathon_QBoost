{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QML Hackathon \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "test_id = test.id\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'E', u'Eg', u'a', u'alpha', u'b', u'beta', u'c',\n",
       "       u'gamma', u'id', u'x_Al', u'x_Ga', u'x_In', u'avg_rs_max',\n",
       "       u'avg_electronegativity', u'avg_rp_max', u'avg_LUMO', u'avg_IP',\n",
       "       u'avg_rd_max', u'avg_EA', u'avg_HOMO', u'avg_mass', u'x_Al_avg',\n",
       "       u'x_Ga_avg', u'x_In_avg', u'a_avg', u'b_avg', u'c_avg',\n",
       "       u'avg_rs_max_avg', u'avg_electronegativity_avg', u'avg_rp_max_avg',\n",
       "       u'avg_LUMO_avg', u'avg_IP_avg', u'avg_rd_max_avg', u'avg_EA_avg',\n",
       "       u'avg_HOMO_avg', u'avg_mass_avg', u'vol_avg', u'alpha_r', u'beta_r',\n",
       "       u'gamma_r', u'vol', u'atomic_density', u'atomic_density_avg', u'Al_0_0',\n",
       "       u'Al_1_0', u'Al_2_0', u'Al_3_0', u'Al_4_0', u'Al_5_0', u'Ga_0_0',\n",
       "       u'Ga_1_0', u'Ga_2_0', u'Ga_3_0', u'Ga_4_0', u'Ga_5_0', u'In_0_0',\n",
       "       u'In_1_0', u'In_2_0', u'In_3_0', u'In_4_0', u'In_5_0', u'Natoms_10.0',\n",
       "       u'Natoms_20.0', u'Natoms_30.0', u'Natoms_40.0', u'Natoms_60.0',\n",
       "       u'Natoms_80.0', u'O_0_0', u'O_1_0', u'O_2_0', u'O_3_0', u'O_4_0',\n",
       "       u'O_5_0', u'sg_12', u'sg_167', u'sg_194', u'sg_206', u'sg_227',\n",
       "       u'sg_33', u'pca_abc', u'pca_AlGaInDensity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_all_data = pd.read_csv('all_data.csv')\n",
    "new_all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 45), (2400,), (2400,), (2400, 2), (600, 45))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# features to use\n",
    "features = ['x_Al', 'x_Ga', 'x_In', 'a', 'b', 'c', 'alpha', 'beta',\n",
    "            'gamma', 'vol', 'atomic_density', 'x_Al_avg','x_Ga_avg', 'x_In_avg', 'a_avg',\n",
    "            'b_avg', 'c_avg', 'vol_avg', 'atomic_density_avg', 'pca_abc', 'pca_AlGaInDensity',\n",
    "            'O_0_0','O_1_0', 'O_2_0', 'O_3_0', 'O_4_0', 'O_5_0', 'Al_0_0', 'Al_1_0', 'Al_2_0', 'Al_3_0', 'Al_4_0', 'Al_5_0', 'Ga_0_0',\n",
    "            'Ga_1_0', 'Ga_2_0', 'Ga_3_0', 'Ga_4_0', 'Ga_5_0', 'In_0_0', 'In_1_0',\n",
    "            'In_2_0', 'In_3_0', 'In_4_0', 'In_5_0',]\n",
    "\n",
    "# two different vectors for pca\n",
    "vector1 = all_data[['a', 'b', 'c']].values\n",
    "vector2 = all_data[['x_Al', 'x_Ga', 'x_In', 'atomic_density_avg']].values\n",
    "\n",
    "# use pca to add new features\n",
    "pca = PCA()\n",
    "pca.fit(vector1)\n",
    "all_data['pca_abc'] = pca.transform(vector1)[:,0]\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(vector2)\n",
    "all_data['pca_AlGaInDensity'] = pca.transform(vector2)[:,0]\n",
    "\n",
    "# scaling the data. Linear models tend to like more normally distributed\n",
    "# I tried training on non-scaled, with slightly worse results\n",
    "scale = StandardScaler()\n",
    "scaled = scale.fit(all_data[features]).transform(all_data[features])\n",
    "\n",
    "X_scale = scaled[:train.shape[0]]\n",
    "X_scaled_test = scaled[train.shape[0]:]\n",
    "\n",
    "X_tr = all_data[:train.shape[0]][features].values\n",
    "X_te = all_data[train.shape[0]:][features].values\n",
    "\n",
    "y1 = np.log1p(train['E'])\n",
    "y2 = np.log1p(train['Eg'])\n",
    "\n",
    "y12 = np.column_stack((y1, y2))\n",
    "\n",
    "X_tr.shape, y1.shape, y2.shape, y12.shape, X_scaled_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preformance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performance matric\n",
    "def rmsle(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypthesis h and targets y\n",
    "\n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    \n",
    "#     h, y = np.expm1(h), np.expm1(y)\n",
    "    \n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run different model for different Target Variables\n",
    "\n",
    "grad_1 = GradientBoostingRegressor(\n",
    "                loss='ls',\n",
    "                learning_rate = 0.0035,\n",
    "                max_depth=7,\n",
    "                n_estimators=1120,\n",
    "                max_features=7,\n",
    "                min_samples_leaf=43,\n",
    "                min_samples_split=14,\n",
    "                min_weight_fraction_leaf=0.01556)\n",
    "\n",
    "grad_2 = GradientBoostingRegressor(\n",
    "                loss='ls',\n",
    "                learning_rate = 0.0035,\n",
    "                max_depth=6,\n",
    "                n_estimators=3275,\n",
    "                max_features=2,\n",
    "                min_samples_leaf=2,\n",
    "                min_samples_split=2,\n",
    "                min_weight_fraction_leaf=0.08012)\n",
    "\n",
    "def assess_grad(X, y_list, model_list):\n",
    "    \"\"\" Used to access model performance. Returns the mean rmsle score of cross validated data\n",
    "    \"\"\"\n",
    "    final = []\n",
    "    best_iter = [[], []]\n",
    "    for idx, y in enumerate(y_list):\n",
    "        kfold = KFold(n_splits=10, shuffle=True)\n",
    "        out = []\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            model = model_list[idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            h =  model.predict(X_test)\n",
    "            e = rmsle(np.expm1(h), np.expm1(y_test))\n",
    "            print(e)\n",
    "            out.append(e)\n",
    "        final.append(np.array(out).mean())\n",
    "                      \n",
    "    return(np.array(final).mean(), np.array(final).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03711007430767033\n",
      "0.03233878998633526\n",
      "0.02968880176799654\n",
      "0.03175961694995181\n",
      "0.03373580313148603\n",
      "0.030356804408733874\n",
      "0.026152474625486935\n",
      "0.03277486103052283\n",
      "0.036101985420334784\n",
      "0.03506747847915937\n",
      "0.09423129499402542\n",
      "0.09500576452238402\n",
      "0.08950503984695904\n",
      "0.08624886933637849\n",
      "0.08438881979985043\n",
      "0.10400580146274513\n",
      "0.10049768957256199\n",
      "0.08472378532859268\n",
      "0.10305272256190769\n",
      "0.06353467023091135\n",
      "Model RMSLE: 0.0615140573882, std: 0.0290053883774\n"
     ]
    }
   ],
   "source": [
    "model = assess_grad(X_tr, [y1, y2], [grad_1, grad_2])\n",
    "print(\"Model RMSLE: {}, std: {}\".format(model[0], model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
