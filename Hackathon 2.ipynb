{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QML Hackathon \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "test_id = test.id\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "\n",
    "train.rename(columns={\n",
    "    'spacegroup' : 'sg',\n",
    "    'number_of_total_atoms' : 'Natoms',\n",
    "    'percent_atom_al' : 'x_Al',\n",
    "    'percent_atom_ga' : 'x_Ga',\n",
    "    'percent_atom_in' : 'x_In',\n",
    "    'lattice_vector_1_ang' : 'a',\n",
    "    'lattice_vector_2_ang' : 'b',\n",
    "    'lattice_vector_3_ang' : 'c',\n",
    "    'lattice_angle_alpha_degree' : 'alpha',\n",
    "    'lattice_angle_beta_degree' : 'beta',\n",
    "    'lattice_angle_gamma_degree' : 'gamma',\n",
    "    'formation_energy_ev_natom' : 'E',\n",
    "    'bandgap_energy_ev' : 'Eg'}, inplace=True)\n",
    "\n",
    "test.rename(columns={\n",
    "    'spacegroup' : 'sg',\n",
    "    'number_of_total_atoms' : 'Natoms',\n",
    "    'percent_atom_al' : 'x_Al',\n",
    "    'percent_atom_ga' : 'x_Ga',\n",
    "    'percent_atom_in' : 'x_In',\n",
    "    'lattice_vector_1_ang' : 'a',\n",
    "    'lattice_vector_2_ang' : 'b',\n",
    "    'lattice_vector_3_ang' : 'c',\n",
    "    'lattice_angle_alpha_degree' : 'alpha',\n",
    "    'lattice_angle_beta_degree' : 'beta',\n",
    "    'lattice_angle_gamma_degree' : 'gamma',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sg', 'Natoms', 'x_Al', 'x_Ga', 'x_In', 'a', 'b', 'c', 'alpha',\n",
       "       'beta', 'gamma', 'E', 'Eg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_all_data = pd.read_csv('./data/all_data.csv')\n",
    "new_all_data.columns\n",
    "all_data = new_all_data\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 45), (2400,), (2400,), (2400, 2), (600, 45))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# features to use\n",
    "features = ['x_Al', 'x_Ga', 'x_In', 'a', 'b', 'c', 'alpha', 'beta',\n",
    "            'gamma', 'vol', 'atomic_density', 'x_Al_avg','x_Ga_avg', 'x_In_avg', 'a_avg',\n",
    "            'b_avg', 'c_avg', 'vol_avg', 'atomic_density_avg', 'pca_abc', 'pca_AlGaInDensity',\n",
    "            'O_0_0','O_1_0', 'O_2_0', 'O_3_0', 'O_4_0', 'O_5_0', 'Al_0_0', 'Al_1_0', 'Al_2_0', 'Al_3_0', 'Al_4_0', 'Al_5_0', 'Ga_0_0',\n",
    "            'Ga_1_0', 'Ga_2_0', 'Ga_3_0', 'Ga_4_0', 'Ga_5_0', 'In_0_0', 'In_1_0',\n",
    "            'In_2_0', 'In_3_0', 'In_4_0', 'In_5_0',]\n",
    "\n",
    "# two different vectors for pca\n",
    "vector1 = all_data[['a', 'b', 'c']].values\n",
    "vector2 = all_data[['x_Al', 'x_Ga', 'x_In', 'atomic_density_avg']].values\n",
    "\n",
    "# use pca to add new features\n",
    "pca = PCA()\n",
    "pca.fit(vector1)\n",
    "all_data['pca_abc'] = pca.transform(vector1)[:,0]\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(vector2)\n",
    "all_data['pca_AlGaInDensity'] = pca.transform(vector2)[:,0]\n",
    "\n",
    "# scaling the data. Linear models tend to like more normally distributed\n",
    "# I tried training on non-scaled, with slightly worse results\n",
    "scale = StandardScaler()\n",
    "scaled = scale.fit(all_data[features]).transform(all_data[features])\n",
    "\n",
    "X_scale = scaled[:train.shape[0]]\n",
    "X_scaled_test = scaled[train.shape[0]:]\n",
    "\n",
    "X_tr = all_data[:train.shape[0]][features].values\n",
    "X_te = all_data[train.shape[0]:][features].values\n",
    "\n",
    "y1 = np.log1p(train['E'])\n",
    "y2 = np.log1p(train['Eg'])\n",
    "\n",
    "y12 = np.column_stack((y1, y2))\n",
    "\n",
    "X_tr.shape, y1.shape, y2.shape, y12.shape, X_scaled_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preformance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performance matric\n",
    "def rmsle(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypthesis h and targets y\n",
    "\n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    \n",
    "#     h, y = np.expm1(h), np.expm1(y)\n",
    "    \n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run different model for different Target Variables\n",
    "\n",
    "grad_1 = GradientBoostingRegressor(\n",
    "                loss='ls',\n",
    "                learning_rate = 0.0035,\n",
    "                max_depth=7,\n",
    "                n_estimators=1120,\n",
    "                max_features=7,\n",
    "                min_samples_leaf=43,\n",
    "                min_samples_split=14,\n",
    "                min_weight_fraction_leaf=0.01556)\n",
    "\n",
    "grad_2 = GradientBoostingRegressor(\n",
    "                loss='ls',\n",
    "                learning_rate = 0.0035,\n",
    "                max_depth=6,\n",
    "                n_estimators=3275,\n",
    "                max_features=2,\n",
    "                min_samples_leaf=2,\n",
    "                min_samples_split=2,\n",
    "                min_weight_fraction_leaf=0.08012)\n",
    "\n",
    "def assess_grad(X, y_list, model_list):\n",
    "    \"\"\" Used to access model performance. Returns the mean rmsle score of cross validated data\n",
    "    \"\"\"\n",
    "    final = []\n",
    "    best_iter = [[], []]\n",
    "    for idx, y in enumerate(y_list):\n",
    "        kfold = KFold(n_splits=10, shuffle=True)\n",
    "        out = []\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            model = model_list[idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            h =  model.predict(X_test)\n",
    "            e = rmsle(np.expm1(h), np.expm1(y_test))\n",
    "            print(e)\n",
    "            out.append(e)\n",
    "        final.append(np.array(out).mean())\n",
    "                      \n",
    "    return(np.array(final).mean(), np.array(final).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031235830292461682\n",
      "0.030213516769038162\n",
      "0.03733221272908664\n",
      "0.03709529431758591\n",
      "0.0345533741913991\n",
      "0.030420868905986463\n",
      "0.03491026564659911\n",
      "0.028142406384270787\n",
      "0.03277225539180304\n",
      "0.029440832491352067\n",
      "0.08524644686741777\n",
      "0.0895614640931458\n",
      "0.08201402621060525\n",
      "0.0803850039770066\n",
      "0.08982694365722622\n",
      "0.09538026848156189\n",
      "0.09421868598431501\n",
      "0.10259336822400718\n",
      "0.10205821036502735\n",
      "0.08889803711063618\n",
      "Model RMSLE: 0.061814965604526616, std: 0.029203279892568317\n"
     ]
    }
   ],
   "source": [
    "model = assess_grad(X_tr, [y1, y2], [grad_1, grad_2])\n",
    "print(\"Model RMSLE: {}, std: {}\".format(model[0], model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.03522487062519504\n",
      "RMSLE: 0.030835353908031056\n",
      "RMSLE: 0.03797183373498328\n",
      "RMSLE: 0.028746763609099585\n",
      "RMSLE: 0.03291541187926484\n",
      "RMSLE: 0.03539575577980152\n",
      "RMSLE: 0.03305602119743682\n",
      "RMSLE: 0.0328463260280417\n",
      "RMSLE: 0.02685749455724478\n",
      "RMSLE: 0.02984019691176692\n",
      "RMSLE: 0.08246473826912223\n",
      "RMSLE: 0.08031301343166705\n",
      "RMSLE: 0.08314740596951575\n",
      "RMSLE: 0.08390854213531491\n",
      "RMSLE: 0.1008357469735944\n",
      "RMSLE: 0.09576484297164943\n",
      "RMSLE: 0.08011960504208634\n",
      "RMSLE: 0.08718077261497703\n",
      "RMSLE: 0.08297010778211764\n",
      "RMSLE: 0.07966571893585024\n",
      "Model RMSLE: 0.05900302611783803, std: 0.026634023294751476\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_1 = XGBRegressor(\n",
    "    learning_rate=0.005,\n",
    "    n_jobs=3,\n",
    "    n_estimators= 1804,\n",
    "    gamma= 0.0,\n",
    "    subsample= 0.222159,\n",
    "    colsample_bytree= 0.5359,\n",
    "    colsample_bylevel= 0.19958,\n",
    "    max_delta_step= 64,\n",
    "    max_depth=28,\n",
    "    min_child_weight= 10,\n",
    "    reg_lambda=0.33038,\n",
    "    silent= True,\n",
    ")\n",
    "\n",
    "xgb_2 = XGBRegressor(\n",
    "    learning_rate=0.005,\n",
    "    n_jobs=3,\n",
    "    n_estimators= 2386,\n",
    "    gamma= 0.0,\n",
    "    subsample= 0.90919,\n",
    "    colsample_bytree= 0.59049,\n",
    "    colsample_bylevel= 0.59404,\n",
    "    max_delta_step= 99,\n",
    "    max_depth=58,\n",
    "    min_child_weight= 85,\n",
    "    reg_lambda= 0.031165789070644215,\n",
    "    silent= True,\n",
    ")\n",
    "def assess_xgb(X, y_list, model_num):\n",
    "    \"\"\" Used to access model performance. Returns the mean rmsle score of cross validated data\n",
    "    \"\"\"\n",
    "    final = []\n",
    "    best_iter = [[], []]\n",
    "    for idx, y in enumerate(y_list):\n",
    "        kfold = KFold(n_splits=10, shuffle=True)\n",
    "        out = []\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            model = model_num[idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            h =  model.predict(X_test)\n",
    "            e = rmsle(np.expm1(h), np.expm1(y_test))\n",
    "            print('RMSLE: {}'.format(e))\n",
    "            out.append(e)\n",
    "        final.append(np.array(out).mean())\n",
    "    return(np.array(final).mean(), np.array(final).std())\n",
    "\n",
    "model = assess_xgb(X_tr, [y1, y2], [xgb_1, xgb_2])\n",
    "print(\"Model RMSLE: {}, std: {}\".format(model[0], model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "\n",
    "# I found these parameterw worked for both y variables\n",
    "cat_1 = CatBoostRegressor(iterations=2300,\n",
    "                          learning_rate=0.020,\n",
    "                          depth=5,\n",
    "                          loss_function='RMSE',\n",
    "                          eval_metric='RMSE',\n",
    "                          od_type='Iter',\n",
    "                          od_wait=50,\n",
    "                         )\n",
    "\n",
    "def assess_cat(X, y_list, model_num):\n",
    "    \"\"\" Used to access model performance. Returns the mean rmsle score of cross validated data\n",
    "    \"\"\"\n",
    "    final = []\n",
    "    best_iter = [[], []]\n",
    "    for idx, y in enumerate(y_list):\n",
    "        kfold = KFold(n_splits=10, shuffle=True)\n",
    "        out = []\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            model = model_num[idx]\n",
    "            model.fit(X_train, y_train, verbose=False)\n",
    "            h =  model.predict(X_test)\n",
    "            e = rmsle(np.expm1(h), np.expm1(y_test))\n",
    "            print('RMSLE: {}'.format(e))\n",
    "            out.append(e)\n",
    "        final.append(np.array(out).mean())\n",
    "    return(np.array(final).mean(), np.array(final).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.03265148892049478\n",
      "RMSLE: 0.032966912284922316\n",
      "RMSLE: 0.03270096213658705\n",
      "RMSLE: 0.03609359217071158\n",
      "RMSLE: 0.028385102571945736\n",
      "RMSLE: 0.03069123434926073\n",
      "RMSLE: 0.03827922222160731\n",
      "RMSLE: 0.028664024544775023\n",
      "RMSLE: 0.036294420153251586\n",
      "RMSLE: 0.027907790008408744\n",
      "RMSLE: 0.10289044143355489\n",
      "RMSLE: 0.0784031133204579\n",
      "RMSLE: 0.09678459741400268\n",
      "RMSLE: 0.09154133403194552\n",
      "RMSLE: 0.0977357574782428\n",
      "RMSLE: 0.08557513678252765\n",
      "RMSLE: 0.07492530340325988\n",
      "RMSLE: 0.08571380810644491\n",
      "RMSLE: 0.08211000238925993\n",
      "RMSLE: 0.0754606515438452\n",
      "Model RMSLE: 0.059788744763275316, std: 0.02732526982707883\n"
     ]
    }
   ],
   "source": [
    "model = assess_cat(X_tr, [y1, y2], [cat_1, cat_1])\n",
    "print(\"Model RMSLE: {}, std: {}\".format(model[0], model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "catboost_cv = CatBoostRegressor(iterations=1200,\n",
    "                            learning_rate=0.03,\n",
    "                            depth=5,\n",
    "                            loss_function='RMSE',\n",
    "                            eval_metric='RMSE',\n",
    "                            random_seed=99,\n",
    "                            od_type='Iter',\n",
    "                            od_wait=50)\n",
    "    \n",
    "def assess_cv_catboost(X, y_list):\n",
    "    \"\"\" Used to access model performance. Returns the mean rmsle score of cross validated data\n",
    "    \"\"\"\n",
    "    final = []\n",
    "    best_iter = [[], []]\n",
    "    for idx, y in enumerate(y_list):\n",
    "        kfold = KFold(n_splits=10, shuffle=True)\n",
    "        out = []\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            # splitting the data up into train, test, and valid sets\n",
    "            X_iter, X_test = X[train_index], X[test_index]\n",
    "            y_iter, y_test = y[train_index], y[test_index]\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(X_iter, y_iter, test_size=0.3)\n",
    "            model =  catboost_cv\n",
    "            model.fit(X_train, y_train,\n",
    "                      eval_set=(X_valid, y_valid),\n",
    "                      use_best_model=True,\n",
    "                      verbose=False)\n",
    "            h =  model.predict(X_test)\n",
    "            e = rmsle(np.expm1(h), np.expm1(y_test))\n",
    "            print('RMSLE: {}'.format(e))\n",
    "            out.append(e)\n",
    "        final.append(np.array(out).mean())\n",
    "    return(np.array(final).mean(), np.array(final).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.03506162050857025\n",
      "RMSLE: 0.03577422553226561\n",
      "RMSLE: 0.030901495220155003\n",
      "RMSLE: 0.03254313256986995\n",
      "RMSLE: 0.03161603188585777\n",
      "RMSLE: 0.027491057083018765\n",
      "RMSLE: 0.03207401960035554\n",
      "RMSLE: 0.029544733541181572\n",
      "RMSLE: 0.03383616987424214\n",
      "RMSLE: 0.03538066670311648\n",
      "RMSLE: 0.07930661019841984\n",
      "RMSLE: 0.09894086270512083\n",
      "RMSLE: 0.08022644595999424\n",
      "RMSLE: 0.08160873103687519\n",
      "RMSLE: 0.08223125819927198\n",
      "RMSLE: 0.0867955337440799\n",
      "RMSLE: 0.09383290322618729\n",
      "RMSLE: 0.09923622601054577\n",
      "RMSLE: 0.08611985621795983\n",
      "RMSLE: 0.08554798098910255\n",
      "Model RMSLE: 0.05990347804030953, std: 0.027481162788446218\n"
     ]
    }
   ],
   "source": [
    "model = assess_cv_catboost(X_tr, [y1, y2])\n",
    "print(\"Model RMSLE: {}, std: {}\".format(model[0], model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
