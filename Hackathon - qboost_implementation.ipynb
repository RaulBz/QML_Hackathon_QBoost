{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qboost: Binary Classification with Quantum Computer\n",
    "\n",
    "The D-Wave quantum computer has been widely studied as a discrete optimization engine that accepts any problem formulated as quadratic unconstrained  binary  optimization  (QUBO). In 2008, Google and D-Wave published a paper, [Training a Binary Classifier with the Quantum Adiabatic Algorithm](https://arxiv.org/pdf/0811.0416.pdf), which describes how the `Qboost` ensemble method makes binary classification amenable to quantum computing: the problem is formulated as a thresholded linear superposition of a set of weak classifiers and the D-Wave quantum computer is  used to optimize the weights in a learning process that strives to minimize the training error and number of weak classifiers.\n",
    "\n",
    "This notebook demonstrates and explains how the Qboost algorithm can be used to solve a binary classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Words on Ensemble Methods\n",
    "\n",
    "Ensemble methods build a strong classifier (an improved model) by combining weak classifiers with the goal of:\n",
    "\n",
    "* decreasing variance (bagging)\n",
    "* decreasing bias (boosting)\n",
    "* improving prediction (voting)\n",
    "\n",
    "![Boosting Algorithm](images/boosting.jpg)\n",
    "\n",
    "### Bagging, Boosting, and Voting\n",
    "\n",
    "The ensemble method produces new training data sets by random sampling with replacement from the original set. In _bagging_, any element has the same probability to appear in a new dataset; in _boosting_, data elements are weighted before they are collected in the new dataset. Another distinction is that bagging is parallelizable but boosting has to be executed sequentially. You can learn more about the differences between these methods here: https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/.\n",
    "\n",
    "Voting operates on labels only. Unlike boosting, the aggeragated classification performance is not used to further polish each weak classifier. Voting has two typical requirements of its collection of  weak classifiers: that there be __many__ and that they be __diverse__.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weak and Strong Classifiers\n",
    "For this reference example we chose the following four classifiers:\n",
    "    1. Adaboost\n",
    "    2. Decision Trees\n",
    "    3. Random Forest\n",
    "    4. Qboost\n",
    "Note that you can replace any of these with any commonly used classification model. Also, an ensemble method can use a strong classifier instead of a weak one, and in this example we embed the Qboost classifier itself, __QboostPlus__ in the following code, with the first three.  \n",
    "\n",
    "### Adaboost\n",
    "Adaboost combines a number of $N$ weak classifiers into a strong one as\n",
    "$$C(x) = sign\\left(\\sum_i^N w_i c_i(x)\\right),$$\n",
    "with $c_i(x) \\in [-1, +1]$ being the $i$-th weak classifier:\n",
    "\n",
    "$$c_i(x) = sign(w'*x + b)$$\n",
    "\n",
    "The loss function of Adaboost is defined as\n",
    "$$\n",
    "L = \\sum_{n=1}^N \\exp\\left\\{ - y_n \\sum_{s=1}^S w_sc_k(x_n)\\right\\}.\n",
    "$$\n",
    "\n",
    "The strong classifier $C(\\cdot)$ is constructed in an iterative fashion. In each iteration, one weak classifier\n",
    "is selected and re-learned to minimize the weighted error function. Its weight is adjusted and renormalized to make sure the sum of all weights equals 1. \n",
    "\n",
    "The final classification model will be decided by a weighted “vote” of all the weak classifiers. \n",
    "\n",
    "### Decision Trees\n",
    "A decision tree builds on a tree structure with non-leaf nodes encoding decision rules and leaf nodes encoding labels. You construct a decision tree by optimizing either entropic or information-theoretic metrics. Controlling the depth of a decision tree indirectly decides the sub-dimension of the dataset. \n",
    "\n",
    "Decision trees are often chosen as the weak classifiers in Adaboost because they are both simple to construct and fast to do inference. The `scikit-learn` package implements its Adaboost method with decision trees of depth 1, also known as _tree stumps_. This reference examples demonstrates an alternative implementation of boosting with a number of deeper decision trees.\n",
    "### Random Forest \n",
    "Random forest is an ensemble method that typically implements bagging on a set of decision trees. By introducing randomness in the selection of an optimized feature in the training of the underlying decision trees, the ensemble diversifies the weightings of its collection of weak classifiers, generally resulting in an improved model.    \n",
    "\n",
    "### Qboost\n",
    "To make use of the optimization power of D-Wave quantum annealer, we needs to formulate our objective function as a quadratic unconstrained binary optimization (QUBO) problem. Therefore, we replace the exponential loss as in Adaboost with the following quadratic loss\n",
    "$$\n",
    "w* = \\arg\\min_w\\left(\\sum_s \\left(\\frac{1}{N}\\sum_n^N w_nc_n(x_s) - y_s\\right)^2\\right) + \\lambda ||w||_0,\n",
    "$$\n",
    "where the regularization term is added to enable controlling of weight sparsity.\n",
    "\n",
    "Note in Qboost, the weight vector is binary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Comparing Performance\n",
    "Now we define functions used in the following experiemnts to train our selected classifiers and provide metrics for comparing performance.\n",
    "\n",
    "First, copy your API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "test_id = test.id\n",
    "train = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get coordinate information\n",
    "\n",
    "ga_cols = []\n",
    "al_cols = []\n",
    "o_cols = []\n",
    "in_cols = []\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for i in range(6):\n",
    "    ga_cols.append(\"Ga_\"+str(i))\n",
    "\n",
    "for i in range(6):\n",
    "    al_cols.append(\"Al_\"+str(i))\n",
    "\n",
    "for i in range(6):\n",
    "    o_cols.append(\"O_\"+str(i))\n",
    "\n",
    "for i in range(6):\n",
    "    in_cols.append(\"In_\"+str(i))\n",
    "\n",
    "\n",
    "\n",
    "ga_df= pd.DataFrame(columns=ga_cols)\n",
    "al_df = pd.DataFrame(columns=al_cols)\n",
    "o_df = pd.DataFrame(columns= o_cols)\n",
    "in_df = pd.DataFrame(columns=in_cols)\n",
    "\n",
    "def get_xyz_data(filename):\n",
    "    pos_data = []\n",
    "    lat_data = []\n",
    "    with open(filename) as f:\n",
    "        for line in f.readlines():\n",
    "            x = line.split()\n",
    "            if x[0] == 'atom':\n",
    "                pos_data.append([np.array(x[1:4], dtype=np.float),x[4]])\n",
    "            elif x[0] == 'lattice_vector':\n",
    "                lat_data.append(np.array(x[1:4], dtype=np.float))\n",
    "    return pos_data, np.array(lat_data)\n",
    "\n",
    "\n",
    "\n",
    "for i in train.id.values:\n",
    "    fn = \"./data/train/{}/geometry.xyz\".format(i)\n",
    "    train_xyz, train_lat = get_xyz_data(fn)\n",
    "    \n",
    "    ga_list = []\n",
    "    al_list = []\n",
    "    o_list = []\n",
    "    in_list = []\n",
    "    \n",
    "    for li in train_xyz:\n",
    "        try:\n",
    "            if li[1] == \"Ga\":\n",
    "                ga_list.append(li[0])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if li[1] == \"Al\":\n",
    "                al_list.append(li[0])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if li[1] == \"In\":\n",
    "                in_list.append(li[0])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if li[1] == \"O\":\n",
    "                o_list.append(li[0])\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        model = PCA(n_components=2)\n",
    "        ga_list = np.array(ga_list)\n",
    "        temp_ga = model.fit_transform(ga_list.transpose())\n",
    "        temp_ga = [item for sublist in temp_ga for item in sublist]\n",
    "       \n",
    "    except:\n",
    "        temp_ga = [0,0,0,0,0,0]\n",
    "#         print i\n",
    "    try:\n",
    "        model = PCA(n_components=2)\n",
    "        al_list = np.array(al_list)\n",
    "        temp_al = model.fit_transform(al_list.transpose())\n",
    "        temp_al = [item for sublist in temp_al for item in sublist]\n",
    "#         print i\n",
    "    except:\n",
    "        temp_al = [0,0,0,0,0,0]\n",
    "#         print i\n",
    "    try:\n",
    "        model = PCA(n_components=2)\n",
    "        o_list = np.array(o_list)\n",
    "        temp_o = model.fit_transform(o_list.transpose())\n",
    "        temp_o = [item for sublist in temp_o for item in sublist]\n",
    "#         print i\n",
    "    except:\n",
    "        temp_o = [0,0,0,0,0,0]\n",
    "#         print i\n",
    "    \n",
    "    try:\n",
    "        model = PCA(n_components=2)\n",
    "        in_list = np.array(in_list)\n",
    "        temp_in = model.fit_transform(in_list.transpose())\n",
    "        temp_in = [item for sublist in temp_in for item in sublist]\n",
    "#         print i\n",
    "    except:\n",
    "        temp_in = [0,0,0,0,0,0]\n",
    "#         print i\n",
    "\n",
    "    temp_ga = pd.DataFrame(temp_ga).transpose()\n",
    "    temp_ga.columns = ga_cols\n",
    "    temp_ga.index = np.array([i])\n",
    "\n",
    "    temp_al = pd.DataFrame(temp_al).transpose()\n",
    "    temp_al.columns = al_cols\n",
    "    temp_al.index = np.array([i])\n",
    "\n",
    "    temp_o = pd.DataFrame(temp_o).transpose()\n",
    "    temp_o.columns = o_cols\n",
    "    temp_o.index = np.array([i])\n",
    "    \n",
    "    temp_in = pd.DataFrame(temp_in).transpose()\n",
    "    temp_in.columns = in_cols\n",
    "    temp_in.index = np.array([i])\n",
    "    \n",
    "    \n",
    "\n",
    "    ga_df = pd.concat([ga_df,temp_ga])\n",
    "    al_df = pd.concat([al_df,temp_al])\n",
    "    o_df = pd.concat([o_df,temp_o])    \n",
    "    in_df = pd.concat([in_df,temp_in])\n",
    "    \n",
    "ga_df[\"id\"] = ga_df.index\n",
    "al_df[\"id\"] = al_df.index\n",
    "o_df[\"id\"] = o_df.index\n",
    "in_df[\"id\"] = in_df.index\n",
    "\n",
    "train = pd.merge(train,ga_df,on = [\"id\"],how = \"left\")\n",
    "train = pd.merge(train,al_df,on = [\"id\"],how = \"left\")\n",
    "train = pd.merge(train,o_df,on = [\"id\"],how = \"left\")\n",
    "train = pd.merge(train,in_df,on = [\"id\"],how = \"left\")\n",
    "\n",
    "ga_df= pd.DataFrame(columns=ga_cols)\n",
    "al_df = pd.DataFrame(columns=al_cols)\n",
    "o_df = pd.DataFrame(columns= o_cols)\n",
    "in_df = pd.DataFrame(columns=in_cols)\n",
    "\n",
    "for i in test.id.values:\n",
    "    fn = \"./data/test/{}/geometry.xyz\".format(i)\n",
    "    test_xyz, test_lat = get_xyz_data(fn)\n",
    "    \n",
    "    ga_list = []\n",
    "    al_list = []\n",
    "    o_list = []\n",
    "    in_list = []\n",
    "    \n",
    "    for li in test_xyz:\n",
    "        try:\n",
    "            if li[1] == \"Ga\":\n",
    "                ga_list.append(li[0])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if li[1] == \"Al\":\n",
    "                al_list.append(li[0])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if li[1] == \"In\":\n",
    "                in_list.append(li[0])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if li[1] == \"O\":\n",
    "                o_list.append(li[0])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "#     ga_list = [item for sublist in ga_list for item in sublist]\n",
    "#     al_list = [item for sublist in al_list for item in sublist]\n",
    "#     o_list = [item for sublist in o_list for item in sublist]\n",
    "   \n",
    "    \n",
    "    try:\n",
    "        model = PCA(n_components=2)\n",
    "        ga_list = np.array(ga_list)\n",
    "        temp_ga = model.fit_transform(ga_list.transpose())\n",
    "        temp_ga = [item for sublist in temp_ga for item in sublist]\n",
    "       \n",
    "    except:\n",
    "        temp_ga = [0,0,0,0,0,0]\n",
    "#         print i\n",
    "    try:\n",
    "        model = PCA(n_components=2)\n",
    "        al_list = np.array(al_list)\n",
    "        temp_al = model.fit_transform(al_list.transpose())\n",
    "        temp_al = [item for sublist in temp_al for item in sublist]\n",
    "#         print i\n",
    "    except:\n",
    "        temp_al = [0,0,0,0,0,0]\n",
    "#         print i\n",
    "    try:\n",
    "        model = PCA(n_components=2)\n",
    "        o_list = np.array(o_list)\n",
    "        temp_o = model.fit_transform(o_list.transpose())\n",
    "        temp_o = [item for sublist in temp_o for item in sublist]\n",
    "#         print i\n",
    "    except:\n",
    "        temp_o = [0,0,0,0,0,0]\n",
    "#         print i\n",
    "    \n",
    "    try:\n",
    "        model = PCA(n_components=2)\n",
    "        in_list = np.array(in_list)\n",
    "        temp_in = model.fit_transform(in_list.transpose())\n",
    "        temp_in = [item for sublist in temp_in for item in sublist]\n",
    "#         print i\n",
    "    except:\n",
    "        temp_in = [0,0,0,0,0,0]\n",
    "#         print i\n",
    "\n",
    "    temp_ga = pd.DataFrame(temp_ga).transpose()\n",
    "    temp_ga.columns = ga_cols\n",
    "    temp_ga.index = np.array([i])\n",
    "\n",
    "    temp_al = pd.DataFrame(temp_al).transpose()\n",
    "    temp_al.columns = al_cols\n",
    "    temp_al.index = np.array([i])\n",
    "\n",
    "    temp_o = pd.DataFrame(temp_o).transpose()\n",
    "    temp_o.columns = o_cols\n",
    "    temp_o.index = np.array([i])\n",
    "    \n",
    "    temp_in = pd.DataFrame(temp_in).transpose()\n",
    "    temp_in.columns = in_cols\n",
    "    temp_in.index = np.array([i])\n",
    "    \n",
    "    \n",
    "\n",
    "    ga_df = pd.concat([ga_df,temp_ga])\n",
    "    al_df = pd.concat([al_df,temp_al])\n",
    "    o_df = pd.concat([o_df,temp_o])    \n",
    "    in_df = pd.concat([in_df,temp_in])\n",
    "    \n",
    "\n",
    "ga_df[\"id\"] = ga_df.index\n",
    "al_df[\"id\"] = al_df.index\n",
    "o_df[\"id\"] = o_df.index\n",
    "in_df[\"id\"] = in_df.index\n",
    "\n",
    "test = pd.merge(test,ga_df,on = [\"id\"],how = \"left\")\n",
    "test = pd.merge(test,al_df,on = [\"id\"],how = \"left\")\n",
    "test = pd.merge(test,o_df,on = [\"id\"],how = \"left\")\n",
    "test = pd.merge(test,in_df,on = [\"id\"],how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.rename(columns={\n",
    "    'spacegroup' : 'sg',\n",
    "    'number_of_total_atoms' : 'Natoms',\n",
    "    'percent_atom_al' : 'x_Al',\n",
    "    'percent_atom_ga' : 'x_Ga',\n",
    "    'percent_atom_in' : 'x_In',\n",
    "    'lattice_vector_1_ang' : 'a',\n",
    "    'lattice_vector_2_ang' : 'b',\n",
    "    'lattice_vector_3_ang' : 'c',\n",
    "    'lattice_angle_alpha_degree' : 'alpha',\n",
    "    'lattice_angle_beta_degree' : 'beta',\n",
    "    'lattice_angle_gamma_degree' : 'gamma',\n",
    "    'formation_energy_ev_natom' : 'E',\n",
    "    'bandgap_energy_ev' : 'Eg'}, inplace=True)\n",
    "\n",
    "test.rename(columns={\n",
    "    'spacegroup' : 'sg',\n",
    "    'number_of_total_atoms' : 'Natoms',\n",
    "    'percent_atom_al' : 'x_Al',\n",
    "    'percent_atom_ga' : 'x_Ga',\n",
    "    'percent_atom_in' : 'x_In',\n",
    "    'lattice_vector_1_ang' : 'a',\n",
    "    'lattice_vector_2_ang' : 'b',\n",
    "    'lattice_vector_3_ang' : 'c',\n",
    "    'lattice_angle_alpha_degree' : 'alpha',\n",
    "    'lattice_angle_beta_degree' : 'beta',\n",
    "    'lattice_angle_gamma_degree' : 'gamma',\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "target = [\n",
    "    'E',\n",
    "    'Eg']\n",
    "\n",
    "all_data = pd.concat((train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve list of elemental properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EA', 'HOMO', 'IP', 'LUMO', 'electronegativity', 'mass', 'rd_max', 'rp_max', 'rs_max']\n"
     ]
    }
   ],
   "source": [
    "def get_prop_list(path_to_element_data):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path_to_element_data (str) - path to folder of elemental property files\n",
    "    Returns:\n",
    "        list of elemental properties (str) which have corresponding .csv files\n",
    "    \"\"\"\n",
    "    return [f[:-4] for f in os.listdir(path_to_element_data)]\n",
    "\n",
    "# folder which contains element data\n",
    "path_to_element_data = './data/elemental-properties/'\n",
    "# get list of properties which have data files\n",
    "properties = get_prop_list(path_to_element_data)\n",
    "print(sorted(properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mass of aluminum is 26.98 amu\n"
     ]
    }
   ],
   "source": [
    "def get_prop(prop, path_to_element_data):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        prop (str) - name of elemental property\n",
    "        path_to_element_data (str) - path to folder of elemental property files\n",
    "    Returns:\n",
    "        dictionary of {element (str) : property value (float)}\n",
    "    \"\"\"\n",
    "    fin = os.path.join(path_to_element_data, prop+'.csv')\n",
    "    with open(fin) as f:\n",
    "        all_els = {line.split(',')[0] : float(line.split(',')[1][:-1]) for line in f}\n",
    "        my_els = ['Al', 'Ga', 'In']\n",
    "        return {el : all_els[el] for el in all_els if el in my_els}\n",
    "\n",
    "# make nested dictionary which maps {property (str) : {element (str) : property value (float)}}\n",
    "prop_dict = {prop : get_prop(prop, path_to_element_data) for prop in properties}\n",
    "print('The mass of aluminum is %.2f amu' % prop_dict['mass']['Al'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# average each property using the composition\n",
    "\n",
    "def avg_prop(x_Al, x_Ga, x_In, prop):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x_Al (float or DataFrame series) - concentration of Al\n",
    "        x_Ga (float or DataFrame series) - concentration of Ga\n",
    "        x_In (float or DataFrame series) - concentration of In\n",
    "        prop (str) - name of elemental property\n",
    "    Returns:\n",
    "        average property for the compound (float or DataFrame series), \n",
    "        weighted by the elemental concentrations\n",
    "    \"\"\"\n",
    "    els = ['Al', 'Ga', 'In']\n",
    "    concentration_dict = dict(zip(els, [x_Al, x_Ga, x_In]))\n",
    "    return np.sum(prop_dict[prop][el] * concentration_dict[el] for el in els)\n",
    "\n",
    "# add averaged properties to DataFrame\n",
    "for prop in properties:\n",
    "    all_data['_'.join(['avg', prop])] = avg_prop(all_data['x_Al'], \n",
    "                                                 all_data['x_Ga'],\n",
    "                                                 all_data['x_In'],\n",
    "                                                 prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the volume of the structure\n",
    "\n",
    "def get_vol(a, b, c, alpha, beta, gamma):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        a (float) - lattice vector 1\n",
    "        b (float) - lattice vector 2\n",
    "        c (float) - lattice vector 3\n",
    "        alpha (float) - lattice angle 1 [radians]\n",
    "        beta (float) - lattice angle 2 [radians]\n",
    "        gamma (float) - lattice angle 3 [radians]\n",
    "    Returns:\n",
    "        volume (float) of the parallelepiped unit cell\n",
    "    \"\"\"\n",
    "    return a*b*c*np.sqrt(1 + 2*np.cos(alpha)*np.cos(beta)*np.cos(gamma)\n",
    "                           - np.cos(alpha)**2\n",
    "                           - np.cos(beta)**2\n",
    "                           - np.cos(gamma)**2)\n",
    "\n",
    "# convert lattice angles from degrees to radians for volume calculation\n",
    "lattice_angles = ['alpha', 'beta', 'gamma']\n",
    "for lang in lattice_angles:\n",
    "    all_data['_'.join([lang, 'r'])] = np.pi * all_data[lang] / 180\n",
    "    \n",
    "# compute the cell volumes \n",
    "all_data['vol'] = get_vol(all_data['a'], all_data['b'], all_data['c'],\n",
    "                          all_data['alpha_r'], all_data['beta_r'], all_data['gamma_r'])\n",
    "\n",
    "# calculate the atomic density\n",
    "all_data['atomic_density'] = all_data['Natoms'] / all_data['vol']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null Values: 0\n"
     ]
    }
   ],
   "source": [
    "# make new features using averages of the following columns by sg group\n",
    "avg_cols = ['x_Al','x_Ga','x_In','a','b','c','avg_rs_max','avg_electronegativity',\n",
    "            'avg_rp_max','avg_LUMO','avg_IP','avg_rd_max','avg_EA','avg_HOMO',\n",
    "            'avg_mass','vol','atomic_density']\n",
    "\n",
    "\n",
    "for col in avg_cols:\n",
    "    new_col = col + \"_avg\"\n",
    "    all_data[new_col] = np.nan\n",
    "    for group in all_data['sg'].unique():\n",
    "        all_data.loc[(all_data['sg'] == group), new_col] = all_data[(all_data['sg'] == group)][col].mean()\n",
    "\n",
    "print('Number of Null Values: {}'.format(pd.isnull(all_data[avg_cols]).sum().sum()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle the values with categorical variables using one hot encoding\n",
    "# This will create a much more sparse set of variables\n",
    "\n",
    "all_data[['sg', 'Natoms']] = all_data[['sg', 'Natoms']].astype(str)\n",
    "all_data = pd.get_dummies(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Correcting Target Variables\n",
    "\n",
    "#  both of the target variables are skewed a bit\n",
    "\n",
    "for col in ['E', 'Eg']:\n",
    "    sns.distplot((train[col]))\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'E', u'Eg', u'a', u'alpha', u'b', u'beta', u'c', u'gamma', u'id',\n",
       "       u'x_Al', u'x_Ga', u'x_In', u'avg_rs_max', u'avg_electronegativity',\n",
       "       u'avg_rp_max', u'avg_LUMO', u'avg_IP', u'avg_rd_max', u'avg_EA',\n",
       "       u'avg_HOMO', u'avg_mass', u'alpha_r', u'beta_r', u'gamma_r', u'vol',\n",
       "       u'atomic_density', u'x_Al_avg', u'x_Ga_avg', u'x_In_avg', u'a_avg',\n",
       "       u'b_avg', u'c_avg', u'avg_rs_max_avg', u'avg_electronegativity_avg',\n",
       "       u'avg_rp_max_avg', u'avg_LUMO_avg', u'avg_IP_avg', u'avg_rd_max_avg',\n",
       "       u'avg_EA_avg', u'avg_HOMO_avg', u'avg_mass_avg', u'vol_avg',\n",
       "       u'atomic_density_avg', u'Al_0_0', u'Al_1_0', u'Al_2_0', u'Al_3_0',\n",
       "       u'Al_4_0', u'Al_5_0', u'Ga_0_0', u'Ga_1_0', u'Ga_2_0', u'Ga_3_0',\n",
       "       u'Ga_4_0', u'Ga_5_0', u'In_0_0', u'In_1_0', u'In_2_0', u'In_3_0',\n",
       "       u'In_4_0', u'In_5_0', u'Natoms_10.0', u'Natoms_20.0', u'Natoms_30.0',\n",
       "       u'Natoms_40.0', u'Natoms_60.0', u'Natoms_80.0', u'O_0_0', u'O_1_0',\n",
       "       u'O_2_0', u'O_3_0', u'O_4_0', u'O_5_0', u'sg_12', u'sg_167', u'sg_194',\n",
       "       u'sg_206', u'sg_227', u'sg_33'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## See data\n",
    "\n",
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 45), (2400,), (2400,), (2400, 2), (600, 45))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# features to use\n",
    "features = ['x_Al', 'x_Ga', 'x_In', 'a', 'b', 'c', 'alpha', 'beta',\n",
    "            'gamma', 'vol', 'atomic_density', 'x_Al_avg','x_Ga_avg', 'x_In_avg', 'a_avg',\n",
    "            'b_avg', 'c_avg', 'vol_avg', 'atomic_density_avg', 'pca_abc', 'pca_AlGaInDensity',\n",
    "            'O_0_0','O_1_0', 'O_2_0', 'O_3_0', 'O_4_0', 'O_5_0', 'Al_0_0', 'Al_1_0', 'Al_2_0', 'Al_3_0', 'Al_4_0', 'Al_5_0', 'Ga_0_0',\n",
    "            'Ga_1_0', 'Ga_2_0', 'Ga_3_0', 'Ga_4_0', 'Ga_5_0', 'In_0_0', 'In_1_0',\n",
    "            'In_2_0', 'In_3_0', 'In_4_0', 'In_5_0',]\n",
    "\n",
    "# two different vectors for pca\n",
    "vector1 = all_data[['a', 'b', 'c']].values\n",
    "vector2 = all_data[['x_Al', 'x_Ga', 'x_In', 'atomic_density_avg']].values\n",
    "\n",
    "# use pca to add new features\n",
    "pca = PCA()\n",
    "pca.fit(vector1)\n",
    "all_data['pca_abc'] = pca.transform(vector1)[:,0]\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(vector2)\n",
    "all_data['pca_AlGaInDensity'] = pca.transform(vector2)[:,0]\n",
    "\n",
    "# scaling the data. Linear models tend to like more normally distributed\n",
    "# I tried training on non-scaled, with slightly worse results\n",
    "scale = StandardScaler()\n",
    "scaled = scale.fit(all_data[features]).transform(all_data[features])\n",
    "\n",
    "X_scale = scaled[:train.shape[0]]\n",
    "X_scaled_test = scaled[train.shape[0]:]\n",
    "\n",
    "X_tr = all_data[:train.shape[0]][features].values\n",
    "X_te = all_data[train.shape[0]:][features].values\n",
    "\n",
    "y1 = np.log1p(train['E'])\n",
    "y2 = np.log1p(train['Eg'])\n",
    "\n",
    "y12 = np.column_stack((y1, y2))\n",
    "\n",
    "X_tr.shape, y1.shape, y2.shape, y12.shape, X_scaled_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performance metric\n",
    "def rmsle(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypthesis h and targets y\n",
    "\n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    \n",
    "#     h, y = np.expm1(h), np.expm1(y)\n",
    "    \n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run different model for different Target Variables\n",
    "\n",
    "grad_1 = GradientBoostingRegressor(\n",
    "                loss='ls',\n",
    "                learning_rate = 0.0035,\n",
    "                max_depth=7,\n",
    "                n_estimators=1120,\n",
    "                max_features=7,\n",
    "                min_samples_leaf=43,\n",
    "                min_samples_split=14,\n",
    "                min_weight_fraction_leaf=0.01556)\n",
    "\n",
    "grad_2 = GradientBoostingRegressor(\n",
    "                loss='ls',\n",
    "                learning_rate = 0.0035,\n",
    "                max_depth=6,\n",
    "                n_estimators=3275,\n",
    "                max_features=2,\n",
    "                min_samples_leaf=2,\n",
    "                min_samples_split=2,\n",
    "                min_weight_fraction_leaf=0.08012)\n",
    "\n",
    "def assess_grad(X, y_list, model_list):\n",
    "    \"\"\" Used to access model performance. Returns the mean rmsle score of cross validated data\n",
    "    \"\"\"\n",
    "    final = []\n",
    "    best_iter = [[], []]\n",
    "    for idx, y in enumerate(y_list):\n",
    "        kfold = KFold(n_splits=10, shuffle=True)\n",
    "        out = []\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            model = model_list[idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            h =  model.predict(X_test)\n",
    "            e = rmsle(np.expm1(h), np.expm1(y_test))\n",
    "            print(e)\n",
    "            out.append(e)\n",
    "        final.append(np.array(out).mean())\n",
    "                      \n",
    "    return(np.array(final).mean(), np.array(final).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029005945806550977\n",
      "0.03069735084928785\n",
      "0.02975926791544472\n",
      "0.03572537732990539\n",
      "0.029012187060581226\n",
      "0.029352636074113585\n",
      "0.03603290932600535\n",
      "0.03223846324000183\n",
      "0.03199300758034223\n",
      "0.03995732788489073\n",
      "0.08111416745113355\n",
      "0.10141046733443633\n",
      "0.09357515607971809\n",
      "0.09594621809346336\n",
      "0.08247904492463455\n",
      "0.09249171661836451\n",
      "0.08787629106977207\n",
      "0.08448670730987279\n",
      "0.09755475553786168\n",
      "0.09258166398526715\n",
      "Model RMSLE: 0.0616645330736, std: 0.0292870857669\n"
     ]
    }
   ],
   "source": [
    "model = assess_grad(X_tr, [y1, y2], [grad_1, grad_2])\n",
    "print(\"Model RMSLE: {}, std: {}\".format(model[0], model[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in your API token:\n",
    "\n",
    "\n",
    "sapi_token = 'CDL8-df1de1d5d76560ee73a82ffca3833a1a444536d3'\n",
    "url = 'https://cloud.dwavesys.com/sapi'\n",
    "token = sapi_token\n",
    "solver_name = 'DW_2000Q_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.datasets.mldata import fetch_mldata\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "\n",
    "from qboost import WeakClassifiers, QBoostClassifier, QboostPlus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us define the `metric` and `train_model` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the functions required in this example\n",
    "\n",
    "#def metric(y, y_pred):\n",
    "#    \"\"\"\n",
    "#    :param y: true label\n",
    "#    :param y_pred: predicted label\n",
    "#    :return: metric score\n",
    "#    \"\"\"\n",
    "#\n",
    "#    return metrics.accuracy_score(y, y_pred)\n",
    "\n",
    "# performance metric\n",
    "def metric(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypthesis h and targets y\n",
    "\n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    \n",
    "#     h, y = np.expm1(h), np.expm1(y)\n",
    "    \n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test, lmd):\n",
    "    \"\"\"\n",
    "    :param X_train: training data\n",
    "    :param y_train: training label\n",
    "    :param X_test: testing data\n",
    "    :param y_test: testing label\n",
    "    :param lmd: lambda used in regularization\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # define parameters used in this function\n",
    "    NUM_READS = 1000\n",
    "    NUM_WEAK_CLASSIFIERS = 30\n",
    "    TREE_DEPTH = 2\n",
    "    DW_PARAMS = {'num_reads': NUM_READS,\n",
    "                 'auto_scale': True,\n",
    "                 'num_spin_reversal_transforms': 10,\n",
    "                 'postprocess': 'optimization',\n",
    "                 }\n",
    "\n",
    "    # define sampler\n",
    "    dwave_sampler = DWaveSampler(token=sapi_token, endpoint = url)\n",
    "    emb_sampler = EmbeddingComposite(dwave_sampler)\n",
    "\n",
    "    N_train = len(X_train)\n",
    "    N_test = len(X_test)\n",
    "    print(\"\\n======================================\")\n",
    "    print(\"Train size: %d, Test size: %d\" %(N_train, N_test))\n",
    "    print('Num weak classifiers:', NUM_WEAK_CLASSIFIERS)\n",
    "\n",
    "    # Preprocessing data\n",
    "    imputer = preprocessing.Imputer()\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    normalizer = preprocessing.Normalizer()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train = normalizer.fit_transform(X_train)\n",
    "\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    X_test = normalizer.fit_transform(X_test)\n",
    "\n",
    "    ## Adaboost\n",
    "    print('\\nAdaboost')\n",
    "    clf1 = AdaBoostClassifier(n_estimators=NUM_WEAK_CLASSIFIERS)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    y_train1 = clf1.predict(X_train)\n",
    "    y_test1 = clf1.predict(X_test)\n",
    "#     print(clf1.estimator_weights_)\n",
    "    print('accu (train): %5.2f'%(metric(y_train, y_train1)))\n",
    "    print('accu (test): %5.2f'%(metric(y_test, y_test1)))\n",
    "\n",
    "    # Ensembles of Decision Tree\n",
    "    print('\\nDecision tree')\n",
    "    clf2 = WeakClassifiers(n_estimators=NUM_WEAK_CLASSIFIERS, max_depth=TREE_DEPTH)\n",
    "    clf2.fit(X_train, y_train)\n",
    "    y_train2 = clf2.predict(X_train)\n",
    "    y_test2 = clf2.predict(X_test)\n",
    "#     print(clf2.estimator_weights)\n",
    "    print('accu (train): %5.2f' % (metric(y_train, y_train2)))\n",
    "    print('accu (test): %5.2f' % (metric(y_test, y_test2)))\n",
    "    \n",
    "    # Random forest\n",
    "    print('\\nRandom Forest')\n",
    "    clf3 = RandomForestClassifier(max_depth=TREE_DEPTH, n_estimators=NUM_WEAK_CLASSIFIERS)\n",
    "    clf3.fit(X_train, y_train)\n",
    "    y_train3 = clf3.predict(X_train)\n",
    "    y_test3 = clf3.predict(X_test)\n",
    "    print('accu (train): %5.2f' % (metric(y_train, y_train3)))\n",
    "    print('accu (test): %5.2f' % (metric(y_test, y_test3)))\n",
    "\n",
    "    # Qboost\n",
    "    print('\\nQBoost')\n",
    "    clf4 = QBoostClassifier(n_estimators=NUM_WEAK_CLASSIFIERS, max_depth=TREE_DEPTH)\n",
    "    clf4.fit(X_train, y_train, emb_sampler, lmd=lmd, **DW_PARAMS)\n",
    "    y_train4 = clf4.predict(X_train)\n",
    "    y_test4 = clf4.predict(X_test)\n",
    "    print(clf4.estimator_weights)\n",
    "    print('accu (train): %5.2f' % (metric(y_train, y_train4)))\n",
    "    print('accu (test): %5.2f' % (metric(y_test, y_test4)))\n",
    "\n",
    "    # QboostPlus\n",
    "    print('\\nQBoostPlus')\n",
    "    clf5 = QboostPlus([clf1, clf2, clf3, clf4])\n",
    "    clf5.fit(X_train, y_train, emb_sampler, lmd=lmd, **DW_PARAMS)\n",
    "    y_train5 = clf5.predict(X_train)\n",
    "    y_test5 = clf5.predict(X_test)\n",
    "    print(clf5.estimator_weights)\n",
    "    print('accu (train): %5.2f' % (metric(y_train, y_train5)))\n",
    "    print('accu (test): %5.2f' % (metric(y_test, y_test5)))\n",
    "\n",
    "    print(\"===========================================================================\")\n",
    "    print(\"Method \\t Adaboost \\t DecisionTree \\t RandomForest \\t Qboost \\t Qboost+\")\n",
    "    print(\"Train\\t %5.2f \\t\\t %5.2f \\t\\t %5.2f \\t\\t %5.2f \\t\\t %5.2f\"% (metric(y_train, y_train1),\n",
    "                                                                         metric(y_train, y_train2),\n",
    "                                                                         metric(y_train, y_train3),\n",
    "                                                                         metric(y_train, y_train4),\n",
    "                                                                         metric(y_train, y_train5),\n",
    "                                                                        ))\n",
    "    print(\"Test\\t %5.2f \\t\\t %5.2f \\t\\t %5.2f \\t\\t %5.2f \\t\\t %5.2f\"% (metric(y_test, y_test1),\n",
    "                                                                       metric(y_test, y_test2),\n",
    "                                                                       metric(y_test, y_test3),\n",
    "                                                                       metric(y_test, y_test4),\n",
    "                                                                       metric(y_test, y_test5)))\n",
    "    print(\"===========================================================================\")\n",
    "    \n",
    "    return [clf1, clf2, clf3, clf4, clf5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Now we're ready to run some experiments.\n",
    "First, import the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Experiment 1: Binary Classfication on the MNIST Dataset \n",
    "This example transforms the MNIST dataset (handwritten digits) into a binary classification problem. We assume all digits that are smaller than 5 are labelled as -1 and the rest digits are labelled as +1.\n",
    "\n",
    "First, let us load the MINIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(2400, 45)\n",
      "(2400,)\n",
      "1920 480\n",
      "Training data size: (1920, 45)\n",
      "Testing data size: (480, 45)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print len(X_tr)\n",
    "#y_train = [y1,y2]\n",
    "y = y1\n",
    "\n",
    "print X_tr.shape\n",
    "print y1.shape\n",
    "\n",
    "idx = np.arange(len(X_tr))\n",
    "#print idx[1:5]\n",
    "np.random.shuffle(idx)  # shuffles index\n",
    "#print idx[1:5]\n",
    "\n",
    "X_train = X_tr[:int(len(idx)*.8)]\n",
    "y_train = y[:int(len(idx)*.8)]\n",
    "\n",
    "X_test = X_tr[int(len(idx)*.8):]\n",
    "y_test = y[int(len(idx)*.8):]\n",
    "\n",
    "print len(X_train), len(X_test)\n",
    "print(\"Training data size: (%d, %d)\" %(X_train.shape))\n",
    "print(\"Testing data size: (%d, %d)\" %(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the model and compare the results of the selected classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================\n",
      "Train size: 1920, Test size: 480\n",
      "('Num weak classifiers:', 30)\n",
      "\n",
      "Adaboost\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-b71c36502572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# start training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-ce9fd241ca6f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, X_test, y_test, lmd)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nAdaboost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_WEAK_CLASSIFIERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0my_train1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0my_test1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Home/anaconda3/envs/env_py2.7/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Home/anaconda3/envs/env_py2.7/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Home/anaconda3/envs/env_py2.7/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Home/anaconda3/envs/env_py2.7/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Home/anaconda3/envs/env_py2.7/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Home/anaconda3/envs/env_py2.7/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Home/anaconda3/envs/env_py2.7/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# start training the model\n",
    "clfs = train_model(X_train, y_train, X_test, y_test, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: for this cell, Graphviz executables must be on systems PATH \n",
    "# You can optionally visualize the decision trees by uncommenting the following code\n",
    "# import graphviz\n",
    "# from sklearn import tree\n",
    "# clf = clfs[0]\n",
    "# graph = graphviz.Source(tree.export_graphviz(clf.estimators_[0], out_file=None))\n",
    "# graph.render(None, view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Wisconsin Breast Cancer\n",
    "\n",
    "This example classifies tumors in scikit-learn's Wisconsis breast cancer dataset as either malignant or benign (binary classification).\n",
    "\n",
    "First, let us load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wisc = load_breast_cancer()\n",
    "\n",
    "idx = np.arange(len(wisc.target))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# train on a random 2/3 and test on the remaining 1/3\n",
    "idx_train = idx[:2*len(idx)//3]\n",
    "idx_test = idx[2*len(idx)//3:]\n",
    "\n",
    "X_train = wisc.data[idx_train]\n",
    "X_test = wisc.data[idx_test]\n",
    "\n",
    "y_train = 2 * wisc.target[idx_train] - 1  # binary -> spin\n",
    "y_test = 2 * wisc.target[idx_test] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25372, 17422, 39047, ..., 33089, 53898, 43637])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "idx_01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the model and compare the results of the selected classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================\n",
      "Train size: 379, Test size: 190\n",
      "('Num weak classifiers:', 30)\n",
      "\n",
      "Adaboost\n",
      "accu (train):  1.00\n",
      "accu (test):  0.97\n",
      "\n",
      "Decision tree\n",
      "accu (train):  1.00\n",
      "accu (test):  0.97\n",
      "\n",
      "Random Forest\n",
      "accu (train):  0.96\n",
      "accu (test):  0.95\n",
      "\n",
      "QBoost\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "accu (train):  1.00\n",
      "accu (test):  0.98\n",
      "\n",
      "QBoostPlus\n",
      "[1 1 1 1]\n",
      "accu (train):  1.00\n",
      "accu (test):  0.98\n",
      "===========================================================================\n",
      "Method \t Adaboost \t DecisionTree \t RandomForest \t Qboost \t Qboost+\n",
      "Train\t  1.00 \t\t  1.00 \t\t  0.96 \t\t  1.00 \t\t  1.00\n",
      "Test\t  0.97 \t\t  0.97 \t\t  0.95 \t\t  0.98 \t\t  0.98\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "clfs = train_model(X_train, y_train, X_test, y_test, 1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
