{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Home/Documents/QML/Hackathon/qml_hackathon\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_tr = np.load('X_train.npy')\n",
    "X_te = np.load('X_test.npy')\n",
    "y1_tr = np.load('y1_train.npy')\n",
    "y2_tr = np.load('y2_train.npy')\n",
    "\n",
    "# Fill in your API token:\n",
    "\n",
    "\n",
    "sapi_token = 'CDL8-df1de1d5d76560ee73a82ffca3833a1a444536d3'\n",
    "url = 'https://cloud.dwavesys.com/sapi'\n",
    "token = sapi_token\n",
    "solver_name = 'c4-sw_sample'#'DW_2000Q_2'\n",
    "\n",
    "# import necessary packages\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.datasets.mldata import fetch_mldata\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "\n",
    "from qboost import WeakClassifiers, QBoostClassifier, QboostPlus\n",
    "\n",
    "\n",
    "# Define the functions required in this example\n",
    "\n",
    "def metric(y, y_pred):\n",
    "    \"\"\"\n",
    "    :param y: true label\n",
    "    :param y_pred: predicted label\n",
    "    :return: metric score\n",
    "    \"\"\"\n",
    "\n",
    "    return metrics.accuracy_score(y, y_pred)\n",
    "\n",
    "# performance metric\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test, lmd):\n",
    "    \"\"\"\n",
    "    :param X_train: training data\n",
    "    :param y_train: training label\n",
    "    :param X_test: testing data\n",
    "    :param y_test: testing label\n",
    "    :param lmd: lambda used in regularization\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # define parameters used in this function\n",
    "    NUM_READS = 1000\n",
    "    NUM_WEAK_CLASSIFIERS = 30\n",
    "    TREE_DEPTH = 4\n",
    "    DW_PARAMS = {'num_reads': NUM_READS,\n",
    "                 'auto_scale': True,\n",
    "                 'num_spin_reversal_transforms': 10,\n",
    "                 'postprocess': 'optimization',\n",
    "                 }\n",
    "\n",
    "    # define sampler\n",
    "    dwave_sampler = DWaveSampler(token=sapi_token, endpoint = url)\n",
    "    emb_sampler = EmbeddingComposite(dwave_sampler)\n",
    "\n",
    "    N_train = len(X_train)\n",
    "    N_test = len(X_test)\n",
    "    print(\"\\n======================================\")\n",
    "    print(\"Train size: %d, Test size: %d\" %(N_train, N_test))\n",
    "    print('Num weak classifiers:', NUM_WEAK_CLASSIFIERS)\n",
    "\n",
    "    # Preprocessing data\n",
    "    imputer = preprocessing.Imputer()\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    normalizer = preprocessing.Normalizer()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_train = normalizer.fit_transform(X_train)\n",
    "\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    X_test = normalizer.fit_transform(X_test)\n",
    "    \n",
    "    ## Adaboost\n",
    "    print('\\nAdaboost')\n",
    "    clf1 = AdaBoostClassifier(n_estimators=NUM_WEAK_CLASSIFIERS)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    y_train1 = clf1.predict(X_train)\n",
    "    y_test1 = clf1.predict(X_test)\n",
    "#     print(clf1.estimator_weights_)\n",
    "    print('accu (train): %5.2f'%(metric(y_train, y_train1)))\n",
    "    print('accu (test): %5.2f'%(metric(y_test, y_test1)))\n",
    "\n",
    "        # Ensembles of Decision Tree\n",
    "    print('\\nDecision tree')\n",
    "    clf2 = WeakClassifiers(n_estimators=NUM_WEAK_CLASSIFIERS, max_depth=TREE_DEPTH)\n",
    "    clf2.fit(X_train, y_train)\n",
    "    y_train2 = clf2.predict(X_train)\n",
    "    y_test2 = clf2.predict(X_test)\n",
    "#     print(clf2.estimator_weights)\n",
    "    print('accu (train): %5.2f' % (metric(y_train, y_train2)))\n",
    "    print('accu (test): %5.2f' % (metric(y_test, y_test2)))\n",
    "    \n",
    "    # Random forest\n",
    "    print('\\nRandom Forest')\n",
    "    clf3 = RandomForestClassifier(max_depth=TREE_DEPTH, n_estimators=NUM_WEAK_CLASSIFIERS)\n",
    "    clf3.fit(X_train, y_train)\n",
    "    y_train3 = clf3.predict(X_train)\n",
    "    y_test3 = clf3.predict(X_test)\n",
    "    print('accu (train): %5.2f' % (metric(y_train, y_train3)))\n",
    "    print('accu (test): %5.2f' % (metric(y_test, y_test3)))\n",
    "    \n",
    "    # Qboost\n",
    "    print('\\nQBoost')\n",
    "    clf4 = QBoostClassifier(n_estimators=NUM_WEAK_CLASSIFIERS, max_depth=TREE_DEPTH)\n",
    "    clf4.fit(X_train, y_train, emb_sampler, lmd=lmd, **DW_PARAMS)\n",
    "    y_train4 = clf4.predict(X_train)\n",
    "    y_test4 = clf4.predict(X_test)\n",
    "    print(clf4.estimator_weights)\n",
    "    print('accu (train): %5.2f' % (metric(y_train, y_train4)))\n",
    "    print('accu (test): %5.2f' % (metric(y_test, y_test4)))\n",
    "\n",
    "#    QboostPlus\n",
    "    print('\\nQBoostPlus')\n",
    "    clf5 = QboostPlus([clf1, clf2, clf3, clf4])\n",
    "    clf5.fit(X_train, y_train, emb_sampler, lmd=lmd, **DW_PARAMS)\n",
    "    y_train5 = clf5.predict(X_train)\n",
    "    y_test5 = clf5.predict(X_test)\n",
    "    print(clf5.estimator_weights)\n",
    "    print('accu (train): %5.2f' % (metric(y_train, y_train5)))\n",
    "    print('accu (test): %5.2f' % (metric(y_test, y_test5)))\n",
    "\n",
    "    \n",
    "    return [clf4]\n",
    "\n",
    "# start training the model\n",
    "\n",
    "idx = np.arange(len(X_tr))\n",
    "np.random.shuffle(idx)  # shuffles index\n",
    "\n",
    "y_train = y1_tr\n",
    "y_bin = 2*(y1_tr >0.25) - 1\n",
    "\n",
    "X_train = X_tr[:int(len(idx)*.8)]\n",
    "y_train = y_bin[:int(len(idx)*.8)]\n",
    "\n",
    "X_test = X_tr[int(len(idx)*.8):]\n",
    "y_test = y_bin[int(len(idx)*.8):]\n",
    "\n",
    "# start training the model\n",
    "#X_train = X_tr\n",
    "#y_train = y1_tr\n",
    "#y_train = 2*(y_train >0.25) - 1\n",
    "#X_test = X_train\n",
    "#y_test = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================\n",
      "Train size: 1920, Test size: 480\n",
      "('Num weak classifiers:', 30)\n",
      "\n",
      "Adaboost\n",
      "accu (train):  0.93\n",
      "accu (test):  0.89\n",
      "\n",
      "Decision tree\n",
      "accu (train):  0.97\n",
      "accu (test):  0.91\n",
      "\n",
      "Random Forest\n",
      "accu (train):  0.92\n",
      "accu (test):  0.90\n",
      "\n",
      "QBoost\n",
      "[1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1]\n",
      "accu (train):  0.94\n",
      "accu (test):  0.88\n",
      "\n",
      "QBoostPlus\n",
      "[1 1 1 1]\n",
      "accu (train):  0.95\n",
      "accu (test):  0.91\n"
     ]
    }
   ],
   "source": [
    "clfs = train_model(X_train, y_train, X_test, y_test, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 3, ..., 2, 5, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create bins and allocate y to each bin\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "y = y1_tr\n",
    "x = X_tr\n",
    "\n",
    "# split into n_classes, or into n_classes bins\n",
    "n_classes = 10\n",
    "bins = np.linspace(np.min(y), np.max(y), num=n_classes)\n",
    "inds = np.digitize(y, bins)\n",
    "\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# implement one versus rest classifier\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "y = inds # label_binarize(inds, classes=bins)\n",
    "#n_classes = y.shape[1]\n",
    "print np.min(y),np.max(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.2,\n",
    "                                                    random_state=0)\n",
    "print len(X_test)\n",
    "\n",
    "#OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "#y_score = classifier.fit(X_train, y_train)\n",
    "#y_pred = classifier.predict(X_test)\n",
    "#acc = accuracy_score(y_test, y_pred)\n",
    "#print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================\n",
      "Train size: 1920, Test size: 480\n",
      "('Num weak classifiers:', 30)\n",
      "\n",
      "Adaboost\n",
      "accu (train):  0.29\n",
      "accu (test):  0.27\n",
      "\n",
      "Decision tree\n",
      "accu (train):  0.10\n",
      "accu (test):  0.08\n",
      "\n",
      "Random Forest\n",
      "accu (train):  0.61\n",
      "accu (test):  0.51\n",
      "\n",
      "QBoost\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "accu (train):  0.10\n",
      "accu (test):  0.08\n",
      "\n",
      "QBoostPlus\n",
      "[1 1 1 1]\n",
      "accu (train):  0.10\n",
      "accu (test):  0.08\n"
     ]
    }
   ],
   "source": [
    "# run qboost with dicrete variables\n",
    "# does not work well\n",
    "\n",
    "clfs = train_model(X_train, y_train, X_test, y_test, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 2 1 6 3 1 2 5 6 4 4 4 2 2 3 2 7 3 4 2 3 2 4 1 1 3 4 4 1 4 3 4 4 4 3 2\n",
      " 6 2 5 1 2 2 4 1 5 1 3 2 4 1 6 2 4 4 2 1 2 3 2 2 2 2 3 6 4 3 4 4 3 6 3 6 2\n",
      " 3 5 5 2 4 2 1 4 2 3 3 3 5 3 4 4 2 3 5 5 4 3 4 3 3 3 4 2 3 4 6 5 4 3 5 6 1\n",
      " 4 3 3 2 1 4 5 5 2 4 2 4 5 6 5 4 2 3 6 3 5 2 4 5 2 7 4 4 2 6 3 1 6 2 2 2 2\n",
      " 5 4 5 3 5 5 5 4 3 3 6 2 3 4 4 6 2 2 4 6 2 3 2 4 5 7 4 4 3 4 2 2 6 5 2 4 4\n",
      " 5 5 4 3 5 4 4 3 3 3 2 2 2 1 3 1 2 3 3 3 6 3 4 5 4 3 4 2 3 5 5 4 3 3 4 3 2\n",
      " 4 1 2 1 2 4 3 3 4 4 5 4 4 4 3 3 2 4 2 2 6 3 3 5 1 2 3 1 4 5 4 4 2 3 4 7 4\n",
      " 2 6 4 2 3 6 2 6 4 2 4 2 5 3 4 4 2 7 2 2 4 4 4 6 3 4 4 4 4 5 3 6 2 5 2 3 5\n",
      " 4 2 3 1 2 3 2 4 5 6 3 4 3 5 3 1 4 2 3 2 4 4 6 1 3 4 2 2 1 5 6 2 3 4 2 3 5\n",
      " 3 6 3 5 3 4 2 2 2 2 5 5 3 3 2 4 4 2 3 3 4 6 4 3 4 3 2 2 4 4 4 3 2 2 3 4 4\n",
      " 2 2 6 4 2 4 4 2 6 5 5 2 2 2 4 2 5 1 3 2 5 4 2 6 3 3 4 5 5 3 2 3 6 4 3 5 4\n",
      " 3 4 2 2 4 3 3 3 4 5 3 6 3 4 1 4 3 4 3 6 1 4 2 6 2 4 3 3 3 5 5 2 4 1 3 5 6\n",
      " 4 4 4 6 2 4 5 1 4 4 4 3 5 4 3 1 6 7 1 3 4 6 3 4 3 3 5 3 3 4 4 6 4 6 6 5] 0.6125\n"
     ]
    }
   ],
   "source": [
    "# one vs rest classifer with AdaBoost\n",
    "# works well, but low performance due to unbalances classes \n",
    "NUM_WEAK_CLASSIFIERS=30\n",
    "classifier = OneVsRestClassifier(AdaBoostClassifier(n_estimators=NUM_WEAK_CLASSIFIERS))\n",
    "y_score = classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print y_pred, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Qboost:  1 / 3\n",
      "Working on Qboost:  2 / 3\n",
      "Working on Qboost:  3 / 3\n",
      "[1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]\n",
      "Accuracy Score: 0.89375\n"
     ]
    }
   ],
   "source": [
    "## One vs Rest classifier\n",
    "\n",
    "y = y1_tr\n",
    "x = X_tr\n",
    "\n",
    "# split into n_classes, or into n_classes bins\n",
    "n_classes = 3\n",
    "bins = np.linspace(np.min(y), np.max(y), num=n_classes)\n",
    "inds = np.digitize(y, bins)\n",
    "\n",
    "\n",
    "# split data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, inds, test_size=.2,\n",
    "                                                    random_state=0)\n",
    "##\n",
    "\n",
    "NUM_READS = 1000\n",
    "NUM_WEAK_CLASSIFIERS = 30\n",
    "TREE_DEPTH = 4\n",
    "DW_PARAMS = {'num_reads': NUM_READS,\n",
    "             'auto_scale': True,\n",
    "             'num_spin_reversal_transforms': 10,\n",
    "             'postprocess': 'optimization',\n",
    "             }\n",
    "\n",
    "# define sampler\n",
    "dwave_sampler = DWaveSampler(token=sapi_token, endpoint = url)\n",
    "emb_sampler = EmbeddingComposite(dwave_sampler)\n",
    "lmd = 0.2\n",
    "\n",
    "classifiers = []\n",
    "predictions = []\n",
    "pred_test_labels = [0]*len(y_test)\n",
    "pred_train_labels = [0]*len(y_train)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    print 'Working on Qboost: ',i+1,'/',n_classes\n",
    "    new_label = 2*(y_train==i+1)-1\n",
    "     \n",
    "    new_label = np.array(new_label)\n",
    "    clf = QBoostClassifier(n_estimators=NUM_WEAK_CLASSIFIERS, max_depth=TREE_DEPTH)\n",
    "    clf.fit(X_train, new_label, emb_sampler, lmd=lmd, **DW_PARAMS)\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    classifiers.append(clf)\n",
    "    predictions.append(y_test_pred)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(len(predictions[i])):\n",
    "        if predictions[i][j] == 1:\n",
    "            pred_test_labels[j] = i+1\n",
    "            \n",
    "print pred_test_labels\n",
    "acc = accuracy_score(y_test, pred_test_labels)\n",
    "\n",
    "print 'Accuracy Score:', acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
